{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d245b80-1d82-4e44-8fef-c80577b94aea",
   "metadata": {},
   "source": [
    "### DOWNLOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f353e31-eddb-43a6-9ae4-6eb1be228011",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\AppData\\Local\\Temp\\ipykernel_17048\\251469463.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  sp500 = yf.download(\"^GSPC\", start=\"1990-01-01\", end=\"2018-12-31\", interval=\"1d\")\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\Joe\\AppData\\Local\\Temp\\ipykernel_17048\\251469463.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  sp500 = yf.download(\"^GSPC\", start=\"1990-01-01\", end=\"2018-12-31\", interval=\"1d\")\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved S&P 500 data to sp500_1990_2018.csv\n",
      "Saved S&P 500 data to sp500_1990_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# Download S&P 500 index data (^GSPC) from 1990-01-01 to 2018-12-31\n",
    "sp500 = yf.download(\"^GSPC\", start=\"1990-01-01\", end=\"2018-12-31\", interval=\"1d\")\n",
    "\n",
    "# Save to CSV\n",
    "sp500.to_csv(\"sp500_1990_2018.csv\")\n",
    "\n",
    "print(\"Saved S&P 500 data to sp500_1990_2018.csv\")\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Download S&P 500 index data (^GSPC) from 1990-01-01 to 2018-12-31\n",
    "sp500 = yf.download(\"^GSPC\", start=\"1990-01-01\", end=\"2018-12-31\", interval=\"1d\")\n",
    "\n",
    "# Save to CSV\n",
    "sp500.to_csv(\"sp500_1990_2018.csv\")\n",
    "\n",
    "print(\"Saved S&P 500 data to sp500_1990_2018.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c8a42-e007-429e-889c-78f31556f11d",
   "metadata": {},
   "source": [
    "### IMPORT INTO PANDAS & CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe4abb04-2967-4c29-b6a5-d38692ad318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Close        High         Low        Open     Volume\n",
      "Date                                                                 \n",
      "1990-01-02  359.690002  359.690002  351.980011  353.399994  162070000\n",
      "1990-01-03  358.760010  360.589996  357.890015  359.690002  192330000\n",
      "1990-01-04  355.670013  358.760010  352.890015  358.760010  177000000\n",
      "1990-01-05  352.200012  355.670013  351.350006  355.670013  158530000\n",
      "1990-01-08  353.790009  354.239990  350.540009  352.200012  140110000\n",
      "Close     float64\n",
      "High      float64\n",
      "Low       float64\n",
      "Open      float64\n",
      "Volume      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Load exactly as-is\n",
    "df = pd.read_csv(\"sp500_1990_2018.csv\")\n",
    "\n",
    "# 2) Drop the two metadata rows: where 'Price' is 'Ticker' or 'Date'\n",
    "df = df[~df[\"Price\"].isin([\"Ticker\", \"Date\"])].copy()\n",
    "\n",
    "# 3) Parse dates and set index\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Price\"])\n",
    "df = df.drop(columns=[\"Price\"]).set_index(\"Date\").sort_index()\n",
    "\n",
    "# 4) Make sure numeric cols are numeric\n",
    "for c in [\"Close\",\"High\",\"Low\",\"Open\",\"Volume\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6739e4-3fb3-4bc8-bf73-e2254b776f71",
   "metadata": {},
   "source": [
    "### feature eng & train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ae6168-d7ce-49bd-b860-9867364ab86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary date: 2010-04-20\n",
      "Shapes: (5104, 7) (2190, 7)\n",
      "Train class dist: {-1: 1275, 0: 2552, 1: 1277}\n",
      "Test  class dist: {-1: 437, 0: 1277, 1: 476}\n",
      "\n",
      "Multinomial Logistic (Q1/Q3 labels)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1      0.386     0.039     0.071       437\n",
      "           0      0.612     0.958     0.747      1277\n",
      "           1      0.403     0.126     0.192       476\n",
      "\n",
      "    accuracy                          0.594      2190\n",
      "   macro avg      0.467     0.374     0.337      2190\n",
      "weighted avg      0.522     0.594     0.491      2190\n",
      "\n",
      "Confusion (rows=true, cols=pred) [-1,0,1]:\n",
      " [[  17  371   49]\n",
      " [  14 1223   40]\n",
      " [  13  403   60]]\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "LOOKBACK_LAGS = 5\n",
    "ROLL_N = 5\n",
    "TRAIN_FRACTION = 0.70     # time-aware 70/30 split\n",
    "\n",
    "# === 0) ASSUMPTIONS ===\n",
    "# df already exists, Date is the DatetimeIndex, and columns include 'Close'\n",
    "import pandas as pd, numpy as np\n",
    "assert isinstance(df.index, pd.DatetimeIndex), \"df must have a DatetimeIndex\"\n",
    "assert \"Close\" in df.columns, \"df must have a 'Close' column\"\n",
    "\n",
    "# === 1) RETURNS ===\n",
    "df = df.copy()\n",
    "df[\"Return\"] = df[\"Close\"].pct_change()\n",
    "df = df.dropna(subset=[\"Return\"])\n",
    "\n",
    "# === 2) PRELIM SPLIT (to compute Q1/Q3 only on train) ===\n",
    "split_idx = int(len(df) * TRAIN_FRACTION)\n",
    "split_date = df.index[split_idx]   # timestamp boundary\n",
    "\n",
    "# Quartiles from TRAIN returns only (no look-ahead)\n",
    "q1 = df.loc[:split_date, \"Return\"].quantile(0.25)\n",
    "q3 = df.loc[:split_date, \"Return\"].quantile(0.75)\n",
    "\n",
    "# === 3) LABELS (Q1/Q3) ===\n",
    "def label_by_quartiles(r, q1, q3):\n",
    "    if r <= q1:  return -1  # Down\n",
    "    if r >= q3:  return  1  # Up\n",
    "    return 0                 # Flat\n",
    "\n",
    "df[\"Label\"] = df[\"Return\"].apply(lambda r: label_by_quartiles(r, q1, q3))\n",
    "\n",
    "# === 4) FEATURES (past-only) ===\n",
    "# lags\n",
    "for lag in range(1, LOOKBACK_LAGS + 1):\n",
    "    df[f\"lag_{lag}\"] = df[\"Return\"].shift(lag)\n",
    "\n",
    "# rolling stats (use only past info -> shift(1) after rolling)\n",
    "df[\"rolling_mean_5\"] = df[\"Return\"].rolling(ROLL_N).mean().shift(1)\n",
    "df[\"rolling_std_5\"]  = df[\"Return\"].rolling(ROLL_N).std().shift(1)\n",
    "\n",
    "# drop rows introduced by shifting/rolling\n",
    "df_feat = df.dropna().copy()\n",
    "\n",
    "# === 5) FINAL SPLIT (use the SAME date boundary; safe after drops) ===\n",
    "FEATURES = [f\"lag_{i}\" for i in range(1, LOOKBACK_LAGS + 1)] + [\"rolling_mean_5\", \"rolling_std_5\"]\n",
    "TARGET = \"Label\"\n",
    "\n",
    "X = df_feat[FEATURES]\n",
    "y = df_feat[TARGET].astype(int)\n",
    "\n",
    "X_train, y_train = X.loc[:split_date], y.loc[:split_date]\n",
    "X_test,  y_test  = X.loc[split_date:],  y.loc[split_date:]\n",
    "\n",
    "print(\"Boundary date:\", split_date.date())\n",
    "print(\"Shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"Train class dist:\", y_train.value_counts().sort_index().to_dict())\n",
    "print(\"Test  class dist:\", y_test.value_counts().sort_index().to_dict())\n",
    "\n",
    "# === 6) QUICK BASELINE (multinomial logistic) ===\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(multi_class=\"multinomial\", max_iter=2000)\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"\\nMultinomial Logistic (Q1/Q3 labels)\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion (rows=true, cols=pred) [-1,0,1]:\\n\",\n",
    "      confusion_matrix(y_test, y_pred, labels=[-1,0,1]))\n",
    "\n",
    "# === 7) OPTIONAL: SAVE ARTIFACTS ===\n",
    "df_feat[FEATURES + [TARGET]].to_csv(\"sp500_model_table_1990_2018.csv\")\n",
    "X_train.assign(Label=y_train).to_csv(\"train_sp500_1990_2018.csv\")\n",
    "X_test.assign(Label=y_test).to_csv(\"test_sp500_1990_2018.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5501e8ce-30f9-45d4-941c-f22f55efa7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               lag_1     lag_2     lag_3     lag_4     lag_5  rolling_mean_5  \\\n",
       " Date                                                                           \n",
       " 1990-01-10 -0.011787  0.004514 -0.009756 -0.008613 -0.002586       -0.005645   \n",
       " 1990-01-11 -0.006607 -0.011787  0.004514 -0.009756 -0.008613       -0.006450   \n",
       " 1990-01-12  0.003513 -0.006607 -0.011787  0.004514 -0.009756       -0.004025   \n",
       " 1990-01-15 -0.024675  0.003513 -0.006607 -0.011787  0.004514       -0.007008   \n",
       " 1990-01-16 -0.008619 -0.024675  0.003513 -0.006607 -0.011787       -0.009635   \n",
       " \n",
       "             rolling_std_5  \n",
       " Date                       \n",
       " 1990-01-10       0.006633  \n",
       " 1990-01-11       0.006410  \n",
       " 1990-01-12       0.007575  \n",
       " 1990-01-15       0.012027  \n",
       " 1990-01-16       0.010172  ,\n",
       " Label\n",
       " -1    2976\n",
       "  0     896\n",
       "  1    3428\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lagged returns (1–5 days)\n",
    "for lag in range(1, 6):\n",
    "    df[f\"lag_{lag}\"] = df[\"Return\"].shift(lag)\n",
    "\n",
    "# Rolling mean / volatility using only past data (shift(1))\n",
    "df[\"rolling_mean_5\"] = df[\"Return\"].rolling(5).mean().shift(1)\n",
    "df[\"rolling_std_5\"]  = df[\"Return\"].rolling(5).std().shift(1)\n",
    "\n",
    "# Drop rows created by shifting/rolling\n",
    "df = df.dropna()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c.startswith(\"lag_\")] + [\"rolling_mean_5\",\"rolling_std_5\"]\n",
    "X = df[feature_cols]\n",
    "y = df[\"Label\"].astype(int)\n",
    "\n",
    "X.head(), y.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b01e17-f71a-426c-ae8a-502b842e8477",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3fd4b48-d2da-4070-9802-9d53ecd7b381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Label</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>rolling_mean_5</th>\n",
       "      <th>rolling_std_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-12</th>\n",
       "      <td>339.929993</td>\n",
       "      <td>348.529999</td>\n",
       "      <td>339.489990</td>\n",
       "      <td>348.529999</td>\n",
       "      <td>183880000</td>\n",
       "      <td>-0.024675</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-15</th>\n",
       "      <td>337.000000</td>\n",
       "      <td>339.940002</td>\n",
       "      <td>336.570007</td>\n",
       "      <td>339.929993</td>\n",
       "      <td>140590000</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.024675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-16</th>\n",
       "      <td>340.750000</td>\n",
       "      <td>340.750000</td>\n",
       "      <td>333.369995</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>186070000</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>-0.024675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-17</th>\n",
       "      <td>337.399994</td>\n",
       "      <td>342.010010</td>\n",
       "      <td>336.260010</td>\n",
       "      <td>340.769989</td>\n",
       "      <td>170470000</td>\n",
       "      <td>-0.009831</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>-0.024675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-18</th>\n",
       "      <td>338.190002</td>\n",
       "      <td>338.380005</td>\n",
       "      <td>333.980011</td>\n",
       "      <td>337.399994</td>\n",
       "      <td>178590000</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009831</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>-0.024675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close        High         Low        Open     Volume  \\\n",
       "Date                                                                    \n",
       "1990-01-12  339.929993  348.529999  339.489990  348.529999  183880000   \n",
       "1990-01-15  337.000000  339.940002  336.570007  339.929993  140590000   \n",
       "1990-01-16  340.750000  340.750000  333.369995  337.000000  186070000   \n",
       "1990-01-17  337.399994  342.010010  336.260010  340.769989  170470000   \n",
       "1990-01-18  338.190002  338.380005  333.980011  337.399994  178590000   \n",
       "\n",
       "              Return  Label     lag_1     lag_2     lag_3     lag_4  lag_5  \\\n",
       "Date                                                                         \n",
       "1990-01-12 -0.024675     -1       NaN       NaN       NaN       NaN    NaN   \n",
       "1990-01-15 -0.008619     -1 -0.024675       NaN       NaN       NaN    NaN   \n",
       "1990-01-16  0.011128      1 -0.008619 -0.024675       NaN       NaN    NaN   \n",
       "1990-01-17 -0.009831     -1  0.011128 -0.008619 -0.024675       NaN    NaN   \n",
       "1990-01-18  0.002341      0 -0.009831  0.011128 -0.008619 -0.024675    NaN   \n",
       "\n",
       "            rolling_mean_5  rolling_std_5  \n",
       "Date                                       \n",
       "1990-01-12             NaN            NaN  \n",
       "1990-01-15             NaN            NaN  \n",
       "1990-01-16             NaN            NaN  \n",
       "1990-01-17             NaN            NaN  \n",
       "1990-01-18             NaN            NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd31ce3-7e9c-4fb5-ba37-1abe9ff1a57f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
