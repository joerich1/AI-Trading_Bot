{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed8ec35-f6b5-475f-8d84-7f3eec95d2fa",
   "metadata": {},
   "source": [
    "### IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e31b91-d4b6-481c-b71d-0ea7e61905a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shifting and dropping 1990 rows:\n",
      "Shapes: (4034, 77) (3018, 77) (4034,) (3018,)\n",
      "Example columns: ['VIX_Close', 'ADS_Index', 'RECBARS', 'fft', '3mth', '10yr', '30yr', 'Aaa', 'Baa', 'term_spread']\n",
      "Unique y_train values: [-1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "# Read train/test feature files (keeping Date temporarily to filter)\n",
    "X_train = pd.read_csv(os.path.join(DATA_DIR, \"X_train.csv\"))\n",
    "X_test  = pd.read_csv(os.path.join(DATA_DIR, \"X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(DATA_DIR, \"y_train.csv\"))[\"0\"]\n",
    "y_test  = pd.read_csv(os.path.join(DATA_DIR, \"y_test.csv\"))[\"0\"]\n",
    "\n",
    "# Now drop Date column (model shouldn't see raw dates)\n",
    "X_train = X_train.drop(columns=[\"Date\"])\n",
    "X_test  = X_test.drop(columns=[\"Date\"])\n",
    "\n",
    "print(\"After shifting and dropping 1990 rows:\")\n",
    "print(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(\"Example columns:\", list(X_train.columns)[:10])\n",
    "print(\"Unique y_train values:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec28553b-6f07-4d7d-9ecc-81e88cb6a765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After selecting ANN feature set (6 predictors × 3 lags):\n",
      "X_train shape: (4034, 18)\n",
      "Example features: ['VIX_Close_lag1', 'VIX_Close_lag2', 'VIX_Close_lag3', 'MACD_lag1', 'MACD_lag2', 'MACD_lag3', 'term_spread_lag1', 'term_spread_lag2', 'term_spread_lag3', 'corp_spread_lag1', 'corp_spread_lag2', 'corp_spread_lag3']\n"
     ]
    }
   ],
   "source": [
    "# drop cols\n",
    "\n",
    "# %%\n",
    "# Select only the 6 predictors used for ANN, each with 3 lags → 18 features total\n",
    "reduced6 = [\"VIX_Close\", \"MACD\", \"term_spread\", \"corp_spread\", \"majcurr_ret\", \"DAX\"]\n",
    "\n",
    "# Build the expected lag feature names (lag1, lag2, lag3)\n",
    "use_cols = [f\"{c}_lag{l}\" for c in reduced6 for l in (1, 2, 3)]\n",
    "\n",
    "# Keep only columns that actually exist in our dataset\n",
    "use_cols = [c for c in use_cols if c in X_train.columns]\n",
    "\n",
    "# Restrict to this reduced feature set\n",
    "X_train = X_train[use_cols].copy()\n",
    "X_test  = X_test[use_cols].copy()\n",
    "\n",
    "print(\"After selecting ANN feature set (6 predictors × 3 lags):\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Example features:\", use_cols[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693765e2-e5c2-425f-95d8-757561a3e5a9",
   "metadata": {},
   "source": [
    "### RUN ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9511907c-d254-46a8-a5c1-4348c011e882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/57 [..............................] - ETA: 18s - loss: 7.3756 - accuracy: 0.2969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 18:13:15.856695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-10-16 18:13:15.881893: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp_2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 16ms/step - loss: 6.4980 - accuracy: 0.3186 - val_loss: 5.8869 - val_accuracy: 0.1935\n",
      "Epoch 2/500\n",
      " 1/57 [..............................] - ETA: 0s - loss: 5.5657 - accuracy: 0.2812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 18:13:16.714282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 12ms/step - loss: 4.8773 - accuracy: 0.3558 - val_loss: 4.5110 - val_accuracy: 0.1935\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 3.6898 - accuracy: 0.4200 - val_loss: 3.4850 - val_accuracy: 0.1911\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 2.8365 - accuracy: 0.4767 - val_loss: 2.7235 - val_accuracy: 0.1886\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 2.2342 - accuracy: 0.5034 - val_loss: 2.1673 - val_accuracy: 0.2035\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.8164 - accuracy: 0.5078 - val_loss: 1.7709 - val_accuracy: 0.2357\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.5320 - accuracy: 0.5090 - val_loss: 1.4957 - val_accuracy: 0.2779\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 1.3420 - accuracy: 0.5087 - val_loss: 1.3093 - val_accuracy: 0.4119\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 1.2177 - accuracy: 0.5059 - val_loss: 1.1856 - val_accuracy: 0.6377\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.1380 - accuracy: 0.5056 - val_loss: 1.1048 - val_accuracy: 0.6402\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 1s 20ms/step - loss: 1.0880 - accuracy: 0.5062 - val_loss: 1.0527 - val_accuracy: 0.6402\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0573 - accuracy: 0.5103 - val_loss: 1.0195 - val_accuracy: 0.6427\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 1.0387 - accuracy: 0.5106 - val_loss: 0.9983 - val_accuracy: 0.6427\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 1s 22ms/step - loss: 1.0277 - accuracy: 0.5095 - val_loss: 0.9849 - val_accuracy: 0.6452\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0213 - accuracy: 0.5095 - val_loss: 0.9763 - val_accuracy: 0.6452\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0175 - accuracy: 0.5087 - val_loss: 0.9707 - val_accuracy: 0.6452\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0154 - accuracy: 0.5062 - val_loss: 0.9670 - val_accuracy: 0.6452\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0140 - accuracy: 0.5070 - val_loss: 0.9645 - val_accuracy: 0.6452\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0132 - accuracy: 0.5078 - val_loss: 0.9628 - val_accuracy: 0.6452\n",
      "Epoch 20/500\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.0127 - accuracy: 0.5081 - val_loss: 0.9615 - val_accuracy: 0.6452\n",
      "Epoch 21/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0123 - accuracy: 0.5084 - val_loss: 0.9604 - val_accuracy: 0.6452\n",
      "Epoch 22/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0120 - accuracy: 0.5078 - val_loss: 0.9596 - val_accuracy: 0.6452\n",
      "Epoch 23/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0117 - accuracy: 0.5087 - val_loss: 0.9588 - val_accuracy: 0.6452\n",
      "Epoch 24/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0114 - accuracy: 0.5084 - val_loss: 0.9581 - val_accuracy: 0.6452\n",
      "Epoch 25/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0112 - accuracy: 0.5087 - val_loss: 0.9574 - val_accuracy: 0.6452\n",
      "Epoch 26/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0110 - accuracy: 0.5087 - val_loss: 0.9568 - val_accuracy: 0.6452\n",
      "Epoch 27/500\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 1.0108 - accuracy: 0.5084 - val_loss: 0.9561 - val_accuracy: 0.6452\n",
      "Epoch 28/500\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 1.0106 - accuracy: 0.5095 - val_loss: 0.9555 - val_accuracy: 0.6452\n",
      "Epoch 29/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0104 - accuracy: 0.5098 - val_loss: 0.9548 - val_accuracy: 0.6452\n",
      "Epoch 30/500\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 1.0102 - accuracy: 0.5103 - val_loss: 0.9542 - val_accuracy: 0.6452\n",
      "Epoch 31/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0100 - accuracy: 0.5106 - val_loss: 0.9536 - val_accuracy: 0.6452\n",
      "Epoch 32/500\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 1.0098 - accuracy: 0.5109 - val_loss: 0.9529 - val_accuracy: 0.6452\n",
      "Epoch 33/500\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 1.0096 - accuracy: 0.5120 - val_loss: 0.9523 - val_accuracy: 0.6452\n",
      "Epoch 34/500\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.5114Restoring model weights from the end of the best epoch: 14.\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 1.0095 - accuracy: 0.5114 - val_loss: 0.9516 - val_accuracy: 0.6452\n",
      "Epoch 34: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 18:13:45.022222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample accuracy:  0.5248\n",
      "Out-of-sample accuracy: 0.4559\n"
     ]
    }
   ],
   "source": [
    "# %% Final ANN (single run, paper’s best hyperparams) — time-safe validation (no leakage)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, optimizers, callbacks, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "# 1️⃣  Select reduced 6 × 3 lags = 18 features\n",
    "reduced6 = [\"VIX_Close\", \"MACD\", \"term_spread\", \"corp_spread\", \"majcurr_ret\", \"DAX\"]\n",
    "feat_cols = [f\"{c}_lag{l}\" for c in reduced6 for l in (1, 2, 3)]\n",
    "feat_cols = [c for c in feat_cols if c in X_train.columns]\n",
    "\n",
    "Xtr = X_train[feat_cols].copy()\n",
    "Xte = X_test[feat_cols].copy()\n",
    "\n",
    "# Map {-1,0,1} → {0,1,2}\n",
    "y_map = {-1: 0, 0: 1, 1: 2}\n",
    "ytr = y_train.map(y_map).astype(int).values\n",
    "yte = y_test.map(y_map).astype(int).values\n",
    "\n",
    "# 2️⃣  Scale features (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "Xtr_s = scaler.fit_transform(Xtr)\n",
    "Xte_s = scaler.transform(Xte)\n",
    "\n",
    "# 3️⃣  Chronological validation split (last 10% of training), no shuffling\n",
    "n = len(Xtr_s)\n",
    "val_size = max(1, int(0.10 * n))\n",
    "X_tr_s, X_va_s = Xtr_s[: n - val_size], Xtr_s[n - val_size :]\n",
    "y_tr,   y_va   = ytr   [: n - val_size], ytr   [n - val_size :]\n",
    "\n",
    "# 4️⃣  Build the model with paper’s settings\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(Xtr_s.shape[1],)),\n",
    "    layers.Dense(5, activation=\"tanh\", kernel_regularizer=regularizers.l2(0.8)),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 5️⃣  Train once on full training data (time-safe val), no shuffle\n",
    "es = callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=20, restore_best_weights=True, verbose=1\n",
    ")\n",
    "history = model.fit(\n",
    "    X_tr_s, y_tr,\n",
    "    validation_data=(X_va_s, y_va),\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    shuffle=False,   # critical for time series\n",
    "    verbose=1,\n",
    "    callbacks=[es]\n",
    ")\n",
    "\n",
    "# 6️⃣  Evaluate\n",
    "train_acc = model.evaluate(Xtr_s, ytr, verbose=0)[1]\n",
    "test_preds = model.predict(Xte_s, verbose=0).argmax(axis=1)\n",
    "test_acc = accuracy_score(yte, test_preds)\n",
    "\n",
    "print(f\"In-sample accuracy:  {train_acc:.4f}\")\n",
    "print(f\"Out-of-sample accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502cd1e-02f5-4c03-aaf6-b9920377611b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML-MAC)",
   "language": "python",
   "name": "ml-mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
