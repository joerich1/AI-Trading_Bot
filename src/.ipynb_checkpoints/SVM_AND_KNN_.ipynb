{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "svm_knn_trainer_fast.py\n",
        "\n",
        "Lean & fast SVM + KNN trainer:\n",
        "- Auto-derives labels from price if y_* look like dates\n",
        "- Binary or 3-class (terciles on TRAIN only)\n",
        "- SVM (RBF + Poly-3) and KNN with *randomized* hyperparameter search\n",
        "- Train-only feature pruning (low-variance + high-corr)\n",
        "- Optional time-series CV\n",
        "- Optional SVM probabilities (off by default for speed)\n",
        "\n",
        "Use --fast to activate the lighter randomized search + 3-fold CV.\n",
        "\n",
        "Outputs -> artifacts/\n",
        "  SVM_predictions.csv, SVM_report.txt, SVM_confusion_matrix.csv\n",
        "  KNN_predictions.csv, KNN_report.txt, KNN_confusion_matrix.csv\n",
        "  meta.json\n",
        "\"\"\"\n",
        "\n",
        "import argparse, json, os, sys\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# ---------------- CLI ----------------\n",
        "def parse_args(argv=None):\n",
        "    ap = argparse.ArgumentParser(description=\"Fast SVM & KNN trainer with randomized search.\", add_help=True)\n",
        "    ap.add_argument(\"--x-train\", default=\"X_train.csv\")\n",
        "    ap.add_argument(\"--x-test\",  default=\"X_test.csv\")\n",
        "    ap.add_argument(\"--y-train\", default=\"y_train.csv\")\n",
        "    ap.add_argument(\"--y-test\",  default=\"y_test.csv\")\n",
        "    ap.add_argument(\"--y-train-col\", default=None, help=\"Force label col in y_train.csv (optional)\")\n",
        "    ap.add_argument(\"--y-test-col\",  default=None, help=\"Force label col in y_test.csv (optional)\")\n",
        "\n",
        "    # derive labels when y_* unusable\n",
        "    ap.add_argument(\"--derive-labels\", action=\"store_true\", help=\"Derive labels from X price columns (ignores y_*)\")\n",
        "    ap.add_argument(\"--price-col\", default=None)\n",
        "    ap.add_argument(\"--horizon\", type=int, default=5)\n",
        "    ap.add_argument(\"--three-class\", action=\"store_true\")\n",
        "\n",
        "    # pruning\n",
        "    ap.add_argument(\"--corr-threshold\", type=float, default=0.98)\n",
        "    ap.add_argument(\"--min-std\", type=float, default=0.0)\n",
        "\n",
        "    # CV style\n",
        "    ap.add_argument(\"--cv\", choices=[\"stratified\", \"timeseries\"], default=\"stratified\")\n",
        "\n",
        "    # scoring\n",
        "    ap.add_argument(\"--scoring\", default=None)\n",
        "\n",
        "    # speed flags\n",
        "    ap.add_argument(\"--fast\", action=\"store_true\", help=\"Use randomized search with smaller spaces and 3-fold CV\")\n",
        "    ap.add_argument(\"--probabilities\", action=\"store_true\", help=\"Enable SVM(probability=True) (slower)\")\n",
        "\n",
        "    ap.add_argument(\"--outdir\", default=\"artifacts\")\n",
        "\n",
        "    # notebook-safe\n",
        "    if argv is None:\n",
        "        args, _ = ap.parse_known_args()\n",
        "    else:\n",
        "        args, _ = ap.parse_known_args(argv)\n",
        "    return args\n",
        "\n",
        "# ---------------- helpers ----------------\n",
        "DATE_HINTS = (\"date\",\"time\",\"timestamp\",\"day\")\n",
        "PRICE_CANDIDATES = [\"Adj Close\",\"Adj_Close\",\"adj_close\",\"Close\",\"close\"]\n",
        "\n",
        "def is_date_like(s: pd.Series) -> bool:\n",
        "    name = (s.name or \"\").lower()\n",
        "    if any(k in name for k in DATE_HINTS): return True\n",
        "    if s.dtype == \"O\":\n",
        "        sample = s.dropna().astype(str).head(50)\n",
        "        if len(sample) and sample.str.match(r\"^\\d{4}[-/]\\d{2}[-/]\\d{2}\").mean() > 0.6:\n",
        "            return True\n",
        "    try:\n",
        "        parsed = pd.to_datetime(s, errors=\"coerce\")\n",
        "        return parsed.notna().mean() > 0.6\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def pick_label_col(df: pd.DataFrame) -> Optional[str]:\n",
        "    pref = [\"y\",\"label\",\"class\",\"target\",\"signal\"]\n",
        "    for p in pref:\n",
        "        for c in df.columns:\n",
        "            if c.lower()==p: return c\n",
        "    candidates = [c for c in df.columns if not is_date_like(df[c])]\n",
        "    if not candidates: return None\n",
        "    best, best_u = None, None\n",
        "    for c in candidates:\n",
        "        u = df[c].nunique(dropna=True)\n",
        "        if 2 <= u <= 10 and (best is None or u < best_u):\n",
        "            best, best_u = c, u\n",
        "    return best or candidates[0]\n",
        "\n",
        "def select_numeric(Xtr, Xte):\n",
        "    Xtrn = Xtr.select_dtypes(include=[\"number\"]).copy()\n",
        "    Xten = Xte.select_dtypes(include=[\"number\"]).copy()\n",
        "    common = [c for c in Xtrn.columns if c in Xten.columns]\n",
        "    if not common:\n",
        "        raise ValueError(\"No overlapping numeric feature columns between X_train and X_test.\")\n",
        "    return Xtrn[common], Xten[common], common\n",
        "\n",
        "def prune_features_train_only(Xtr_num: pd.DataFrame, Xte_num: pd.DataFrame, min_std: float, corr_thr: float):\n",
        "    stds = Xtr_num.std(ddof=0)\n",
        "    keep = stds[stds > min_std].index.tolist()\n",
        "    Xtr_f = Xtr_num[keep].copy()\n",
        "    Xte_f = Xte_num[keep].copy()\n",
        "\n",
        "    if Xtr_f.shape[1] > 1:\n",
        "        corr = Xtr_f.corr().abs()\n",
        "        upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "        to_drop = [col for col in upper.columns if (upper[col] >= corr_thr).any()]\n",
        "    else:\n",
        "        to_drop = []\n",
        "    kept = [c for c in Xtr_f.columns if c not in to_drop]\n",
        "    return Xtr_f[kept], Xte_f[kept], kept, {\"dropped_low_variance\": [c for c in Xtr_num.columns if c not in keep],\n",
        "                                            \"dropped_high_corr\": to_drop}\n",
        "\n",
        "def encode_labels(ytr, yte):\n",
        "    if ytr.dtype == \"O\" or yte.dtype == \"O\":\n",
        "        le = LabelEncoder()\n",
        "        ytr_enc = pd.Series(le.fit_transform(ytr), name=\"y\")\n",
        "        unknown = set(yte.unique()) - set(le.classes_)\n",
        "        if unknown:\n",
        "            raise ValueError(f\"y_test has unseen labels vs y_train, e.g. {list(sorted(unknown))[:5]}\")\n",
        "        yte_enc = pd.Series(le.transform(yte), name=\"y\")\n",
        "        return ytr_enc, yte_enc, le.classes_.tolist()\n",
        "    return pd.Series(ytr.values, name=\"y\"), pd.Series(yte.values, name=\"y\"), sorted(pd.unique(ytr))\n",
        "\n",
        "def find_price_col(df: pd.DataFrame, override: Optional[str]=None) -> str:\n",
        "    if override:\n",
        "        if override not in df.columns: raise ValueError(f\"--price-col '{override}' not in X.\")\n",
        "        return override\n",
        "    for c in PRICE_CANDIDATES:\n",
        "        if c in df.columns: return c\n",
        "    for c in df.columns:\n",
        "        if \"close\" in c.lower(): return c\n",
        "    raise ValueError(\"No price column found.\")\n",
        "\n",
        "def derive_labels_from_price(Xtr_raw, Xte_raw, price_col, H=5, three_class=False):\n",
        "    Xtr = Xtr_raw.copy(); Xte = Xte_raw.copy()\n",
        "    def fwd_ret(x, h): return x.shift(-h)/x - 1.0\n",
        "    ytr_c = fwd_ret(Xtr[price_col], H)\n",
        "    yte_c = fwd_ret(Xte[price_col], H)\n",
        "    vt, ve = ytr_c.notna(), yte_c.notna()\n",
        "    Xtr, Xte = Xtr.loc[vt], Xte.loc[ve]\n",
        "    ytr_c, yte_c = ytr_c.loc[vt], yte_c.loc[ve]\n",
        "    if three_class:\n",
        "        q1, q3 = ytr_c.quantile([0.25, 0.75])\n",
        "        def terc(r): return -1 if r <= q1 else (1 if r >= q3 else 0)\n",
        "        ytr = ytr_c.apply(terc); yte = yte_c.apply(terc)\n",
        "    else:\n",
        "        ytr = (ytr_c > 0).astype(int); yte = (yte_c > 0).astype(int)\n",
        "    return Xtr, Xte, ytr, yte\n",
        "\n",
        "# ---------------- training ----------------\n",
        "def fit_eval_fast(Xtr_num, Xte_num, ytr, yte, feature_cols, scoring, outdir, cv_type, probs):\n",
        "    n_classes = len(np.unique(ytr))\n",
        "    scoring = scoring or (\"f1_macro\" if n_classes>2 else \"f1\")\n",
        "\n",
        "    num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                         (\"scaler\", StandardScaler())])\n",
        "    preprocess = ColumnTransformer([(\"num\", num_pipe, feature_cols)], remainder=\"drop\")\n",
        "\n",
        "    # CV\n",
        "    cv = TimeSeriesSplit(n_splits=3) if cv_type==\"timeseries\" else StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "    # ---------- SVM ----------\n",
        "    svm = Pipeline([(\"prep\", preprocess), (\"clf\", SVC(probability=probs))])\n",
        "\n",
        "    # Randomized param dists (compact, effective)\n",
        "    from scipy.stats import loguniform\n",
        "    svm_search_space = [\n",
        "        {   # RBF\n",
        "            \"clf__kernel\": [\"rbf\"],\n",
        "            \"clf__C\": loguniform(1e-1, 1e1),        # ~0.1..10\n",
        "            \"clf__gamma\": [\"scale\", 1e-2, 5e-2],    # small set\n",
        "            \"clf__class_weight\": [None, \"balanced\"]\n",
        "        },\n",
        "        {   # Poly-3\n",
        "            \"clf__kernel\": [\"poly\"],\n",
        "            \"clf__degree\": [3],\n",
        "            \"clf__C\": loguniform(1e-1, 1e1),\n",
        "            \"clf__gamma\": [\"scale\", 1e-2],\n",
        "            \"clf__coef0\": [0.0, 1.0],\n",
        "            \"clf__class_weight\": [None, \"balanced\"]\n",
        "        }\n",
        "    ]\n",
        "    svm_rs = RandomizedSearchCV(\n",
        "        svm, svm_search_space, n_iter=12, cv=cv, scoring=scoring,\n",
        "        n_jobs=-1, refit=True, verbose=0, random_state=13\n",
        "    )\n",
        "\n",
        "    # ---------- KNN ----------\n",
        "    knn = Pipeline([(\"prep\", preprocess), (\"clf\", KNeighborsClassifier())])\n",
        "    knn_search_space = {\n",
        "        \"clf__n_neighbors\": [11, 31, 51, 101],\n",
        "        \"clf__weights\": [\"uniform\", \"distance\"],\n",
        "        \"clf__p\": [1, 2],              # Manhattan vs Euclidean\n",
        "        \"clf__leaf_size\": [20, 30, 40] # minor speed/accuracy tweak\n",
        "    }\n",
        "    knn_rs = RandomizedSearchCV(\n",
        "        knn, knn_search_space, n_iter=10, cv=cv, scoring=scoring,\n",
        "        n_jobs=-1, refit=True, verbose=0, random_state=13\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] RandomizedSearchCV (SVM) with {svm_rs.n_iter} samples; scoring={scoring}\")\n",
        "    svm_rs.fit(Xtr_num, ytr)\n",
        "    print(f\"[INFO] RandomizedSearchCV (KNN) with {knn_rs.n_iter} samples; scoring={scoring}\")\n",
        "    knn_rs.fit(Xtr_num, ytr)\n",
        "\n",
        "    def evaluate(model, name):\n",
        "        yhat = model.predict(Xte_num)\n",
        "        acc = accuracy_score(yte, yhat)\n",
        "        bal = balanced_accuracy_score(yte, yhat)\n",
        "        f1m = f1_score(yte, yhat, average=\"macro\" if n_classes>2 else \"binary\")\n",
        "        rep = classification_report(yte, yhat, digits=3)\n",
        "        cm  = confusion_matrix(yte, yhat)\n",
        "        os.makedirs(outdir, exist_ok=True)\n",
        "        pd.DataFrame({\"y_true\": yte, \"y_pred\": yhat}).to_csv(os.path.join(outdir, f\"{name}_predictions.csv\"), index=False)\n",
        "        with open(os.path.join(outdir, f\"{name}_report.txt\"), \"w\") as f: f.write(rep)\n",
        "        pd.DataFrame(cm).to_csv(os.path.join(outdir, f\"{name}_confusion_matrix.csv\"), index=False)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"{name} best_params: {model.best_params_}\")\n",
        "        print(f\"Accuracy={acc:.4f}  BalancedAcc={bal:.4f}  F1({'macro' if n_classes>2 else 'binary'})={f1m:.4f}\")\n",
        "        print(\"Confusion matrix:\\n\", cm)\n",
        "        print(\"Classification report:\\n\", rep)\n",
        "        return {\"best_params\": model.best_params_, \"accuracy\": acc, \"balanced_accuracy\": bal, \"f1_macro\": f1m}\n",
        "\n",
        "    svm_metrics = evaluate(svm_rs, \"SVM\")\n",
        "    knn_metrics = evaluate(knn_rs, \"KNN\")\n",
        "    return n_classes, svm_metrics, knn_metrics, svm_rs.best_params_, knn_rs.best_params_\n",
        "\n",
        "# ---------------- main ----------------\n",
        "def main(argv=None):\n",
        "    args = parse_args(argv)\n",
        "\n",
        "    # load X\n",
        "    Xtr_raw = pd.read_csv(args.x_train)\n",
        "    Xte_raw = pd.read_csv(args.x_test)\n",
        "\n",
        "    # labels\n",
        "    use_derivation = args.derive_labels\n",
        "    if not use_derivation:\n",
        "        try:\n",
        "            ytr_df = pd.read_csv(args.y_train); yte_df = pd.read_csv(args.y_test)\n",
        "            ytr_col = args.y_train_col or pick_label_col(ytr_df)\n",
        "            yte_col = args.y_test_col  or pick_label_col(yte_df)\n",
        "            if (ytr_col is None) or (yte_col is None) or is_date_like(ytr_df[ytr_col]) or is_date_like(yte_df[yte_col]):\n",
        "                print(\"[WARN] y_* unusable (likely dates). Deriving labels from X.\")\n",
        "                use_derivation = True\n",
        "            else:\n",
        "                ytr = ytr_df[ytr_col]; yte = yte_df[yte_col]\n",
        "                XtrL, XteL = Xtr_raw.copy(), Xte_raw.copy()\n",
        "        except Exception:\n",
        "            print(\"[WARN] Failed to parse y_*; deriving labels from X.\")\n",
        "            use_derivation = True\n",
        "\n",
        "    if use_derivation:\n",
        "        price_col = find_price_col(Xtr_raw, args.price_col)\n",
        "        if price_col not in Xte_raw.columns:\n",
        "            raise ValueError(f\"Price column '{price_col}' not found in X_test.\")\n",
        "        XtrL, XteL, ytr, yte = derive_labels_from_price(\n",
        "            Xtr_raw, Xte_raw, price_col=price_col, H=args.horizon, three_class=args.three_class\n",
        "        )\n",
        "\n",
        "    # numeric + pruning\n",
        "    Xtr_num, Xte_num, feature_cols = select_numeric(XtrL, XteL)\n",
        "    Xtr_num, Xte_num, kept_cols, prune_meta = prune_features_train_only(\n",
        "        Xtr_num, Xte_num, min_std=args.min_std, corr_thr=args.corr_threshold\n",
        "    )\n",
        "\n",
        "    # label encoding if needed\n",
        "    if ytr.dtype == \"O\" or yte.dtype == \"O\":\n",
        "        le = LabelEncoder()\n",
        "        ytr = pd.Series(le.fit_transform(ytr), name=\"y\")\n",
        "        unknown = set(yte.unique()) - set(le.classes_)\n",
        "        if unknown:\n",
        "            raise ValueError(f\"y_test contains unseen labels vs y_train (e.g., {list(sorted(unknown))[:5]})\")\n",
        "        yte = pd.Series(le.transform(yte), name=\"y\")\n",
        "\n",
        "    # train & eval (FAST path always on in this script)\n",
        "    n_classes, svm_metrics, knn_metrics, svm_bp, knn_bp = fit_eval_fast(\n",
        "        Xtr_num, Xte_num, ytr, yte, kept_cols,\n",
        "        scoring=args.scoring, outdir=args.outdir,\n",
        "        cv_type=(\"timeseries\" if args.cv==\"timeseries\" else \"stratified\"),\n",
        "        probs=args.probabilities  # keep False unless needed\n",
        "    )\n",
        "\n",
        "    meta = {\n",
        "        \"derived_labels\": use_derivation,\n",
        "        \"n_classes\": int(n_classes),\n",
        "        \"horizon\": args.horizon,\n",
        "        \"three_class\": args.three_class,\n",
        "        \"cv\": args.cv,\n",
        "        \"scoring\": args.scoring or (\"f1_macro\" if n_classes>2 else \"f1\"),\n",
        "        \"feature_count_before\": len(feature_cols),\n",
        "        \"feature_count_after\": len(kept_cols),\n",
        "        \"dropped_low_variance\": prune_meta[\"dropped_low_variance\"],\n",
        "        \"dropped_high_corr\": prune_meta[\"dropped_high_corr\"],\n",
        "        \"feature_sample\": kept_cols[:20],\n",
        "        \"svm\": svm_metrics,\n",
        "        \"knn\": knn_metrics,\n",
        "        \"svm_best_params\": svm_bp,\n",
        "        \"knn_best_params\": knn_bp,\n",
        "    }\n",
        "    os.makedirs(args.outdir, exist_ok=True)\n",
        "    with open(os.path.join(args.outdir, \"meta.json\"), \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "    print(\"\\n[DONE] Results saved in:\", os.path.abspath(args.outdir))\n",
        "    return meta\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bum7BtOl0WE6",
        "outputId": "ddc99b08-2b54-4a69-c581-84f18fda44ca"
      },
      "id": "Bum7BtOl0WE6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] y_* unusable (likely dates). Deriving labels from X.\n",
            "[INFO] RandomizedSearchCV (SVM) with 12 samples; scoring=f1\n",
            "[INFO] RandomizedSearchCV (KNN) with 10 samples; scoring=f1\n",
            "\n",
            "================================================================================\n",
            "SVM best_params: {'clf__C': np.float64(0.4352940519041148), 'clf__class_weight': 'balanced', 'clf__coef0': 0.0, 'clf__degree': 3, 'clf__gamma': 0.01, 'clf__kernel': 'poly'}\n",
            "Accuracy=0.5383  BalancedAcc=0.5502  F1(binary)=0.6081\n",
            "Confusion matrix:\n",
            " [[ 543 1049]\n",
            " [ 342 1079]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.614     0.341     0.438      1592\n",
            "           1      0.507     0.759     0.608      1421\n",
            "\n",
            "    accuracy                          0.538      3013\n",
            "   macro avg      0.560     0.550     0.523      3013\n",
            "weighted avg      0.563     0.538     0.518      3013\n",
            "\n",
            "\n",
            "================================================================================\n",
            "KNN best_params: {'clf__weights': 'uniform', 'clf__p': 1, 'clf__n_neighbors': 11, 'clf__leaf_size': 20}\n",
            "Accuracy=0.5270  BalancedAcc=0.5255  F1(binary)=0.4984\n",
            "Confusion matrix:\n",
            " [[880 712]\n",
            " [713 708]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.552     0.553     0.553      1592\n",
            "           1      0.499     0.498     0.498      1421\n",
            "\n",
            "    accuracy                          0.527      3013\n",
            "   macro avg      0.526     0.526     0.526      3013\n",
            "weighted avg      0.527     0.527     0.527      3013\n",
            "\n",
            "\n",
            "[DONE] Results saved in: /content/artifacts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dRM_Tjnb7N8R"
      },
      "id": "dRM_Tjnb7N8R",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}